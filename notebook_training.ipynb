{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from transformers import pipeline\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "app_id = \"com.instagram.android\"\n",
    "df = pd.read_csv(f\"{app_id}_reviews.csv\")\n",
    "\n",
    "# Preprocessing function\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stop_words = set(stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "# Function for text cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['content'].astype(str).apply(clean_text)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('cleaned_reviews.csv', index=False)\n",
    "print('Data preprocessing completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment labeling completed.\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-trained BERT Sentiment Model\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    result = sentiment_pipeline(text)[0]['label']\n",
    "    return {'LABEL_0': 'negative', 'LABEL_1': 'neutral', 'LABEL_2': 'positive'}.get(result, 'neutral')\n",
    "\n",
    "# Apply sentiment prediction\n",
    "df['sentiment'] = df['cleaned_text'].apply(predict_sentiment)\n",
    "df.to_csv('labeled_reviews.csv', index=False)\n",
    "print(\"Sentiment labeling completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction (TF-IDF + Word2Vec)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
    "pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out()).to_csv(\"tfidf_features.csv\", index=False)\n",
    "\n",
    "# Word2Vec Feature Extraction\n",
    "tokenized_text = df['cleaned_text'].apply(lambda x: x.split())\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=2, workers=4)\n",
    "word2vec_model.save(\"word2vec.model\")\n",
    "\n",
    "print(\"Feature extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert text to vector\n",
    "def vectorize_text(text, model):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(100)\n",
    "\n",
    "X_w2v = np.array([vectorize_text(text, word2vec_model) for text in df['cleaned_text']])\n",
    "\n",
    "# Label Encoding\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "df['label'] = df['sentiment'].map(label_mapping)\n",
    "\n",
    "# Split Data\n",
    "# Split Data Sekali untuk Konsistensi\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.index, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Ambil fitur berdasarkan indeks yang sama\n",
    "X_train_tfidf = X_tfidf[X_train]\n",
    "X_test_tfidf = X_tfidf[X_test]\n",
    "\n",
    "X_train_w2v = X_w2v[X_train]\n",
    "X_test_w2v = X_w2v[X_test]\n",
    "\n",
    "# Handling Class Imbalance (SMOTE)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_tfidf, y_train_tfidf = smote.fit_resample(X_train_tfidf, y_train)\n",
    "X_train_w2v, y_train_w2v = smote.fit_resample(X_train_w2v, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy: 0.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.07        16\n",
      "           1       0.34      0.65      0.44       161\n",
      "           2       0.98      0.93      0.95      3023\n",
      "\n",
      "    accuracy                           0.91      3200\n",
      "   macro avg       0.46      0.55      0.49      3200\n",
      "weighted avg       0.94      0.91      0.92      3200\n",
      "\n",
      "Random Forest Accuracy: 0.87375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.26      0.80      0.40       161\n",
      "           2       0.98      0.88      0.93      3023\n",
      "\n",
      "    accuracy                           0.87      3200\n",
      "   macro avg       0.42      0.56      0.44      3200\n",
      "weighted avg       0.94      0.87      0.90      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.92375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.39      0.70      0.50       161\n",
      "           2       0.98      0.94      0.96      3023\n",
      "\n",
      "    accuracy                           0.92      3200\n",
      "   macro avg       0.46      0.55      0.49      3200\n",
      "weighted avg       0.94      0.92      0.93      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and Evaluate SVM Model\n",
    "svm_model = SVC(kernel='linear', C=1.0)\n",
    "svm_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "print(\"SVM Model Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Train and Evaluate Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=500, max_depth=30, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Train and Evaluate XGBoost Model\n",
    "xgb_model = XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, random_state=42)\n",
    "xgb_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved.\n"
     ]
    }
   ],
   "source": [
    "# Save Best Model\n",
    "joblib.dump(xgb_model, 'best_model.pkl')\n",
    "print(\"Best model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
